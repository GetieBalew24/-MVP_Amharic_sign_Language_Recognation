{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":393},"executionInfo":{"elapsed":3680,"status":"error","timestamp":1678282790548,"user":{"displayName":"Getie Balew","userId":"04202773499671067541"},"user_tz":-180},"id":"oRdtUQX431EQ","outputId":"64169cb3-f16b-40ed-d15e-601ede24085b"},"outputs":[],"source":["\n","#from Segementation import segment_face\n","#from ESLR_Net import ESLR_Net\n","#from model_bel import model_bel\n","#from VGGNet import VGGNet\n","#from AlexNet import AlexNet\n","#from GoogLeNet import GoogLeNet\n","import os \n","import easydict\n","import matplotlib.pyplot as plt\n","from imutils import paths\n","import cv2\n","import numpy as np\n","import argparse\n","from keras.losses import categorical_crossentropy\n","from keras.preprocessing.image import img_to_array\n","from keras.optimizers import Adam, Adamax\n","from keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint\n","from keras.models import load_model\n","from keras.regularizers import l2\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from PIL import Image\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":356317,"status":"ok","timestamp":1613622440660,"user":{"displayName":"Getie Balew","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnGW8p61D5iT4V8FLdNn_ApOAQSp8ES9uosL9e=s64","userId":"04202773499671067541"},"user_tz":480},"id":"9aRggBeqrBh-","outputId":"7f0ae1fc-e542-4f14-ff39-f746291cc773"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2KoDi6W7-qu_"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4fNy2mhm31EZ"},"outputs":[],"source":["batch_size = 32\n","num_epoch = 50\n","image_size = 128\n","IMAGE_DIMS = (128, 128, 3)#if u use normal RGB then the dimension will be 3 or if u applay segementation the dimension will be 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":475,"status":"ok","timestamp":1677649810458,"user":{"displayName":"Getie Balew","userId":"04202773499671067541"},"user_tz":480},"id":"Ab9tAaOS31Ee","outputId":"ae70930f-4731-4692-ae4d-bc58c6159097"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] loading images...\n"]}],"source":["print(\"[INFO] loading images...\")\n","imagePaths = paths.list_images('/content/drive/My Drive/Implementation detection/Dataset')\n","data = []\n","labels = []\n","# loop over our input images\n","for imagePath in imagePaths:\n","    # load the image, pre-process it, and store it in the data list\n","    # load the input image from disk, resize it to 200x200 pixels, scale\n","    image = cv2.imread(imagePath)   # if you run with out segmentation \n","    #image = cv2.imdecode(np.fromfile(imagePath, dtype=np.uint8), 0) # if you applly segmentation\n","    #image = cv2.resize(image, (128,128))\n","    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n","    # image = Segment_face.face_Segment(image)\n","    #image = Segment_skin.skin_Segment(image)\n","    #image = Segmentation.segment_steem(image)\n","    #filters = gabfilter.build_filters()\n","    #image = gabfilter.process(image, filters)\n","    #print(imagePath)\n","    #plt.imshow(image)\n","\n","    image = img_to_array(image)        \n","    \n","    data.append(image)\n","     \n","    # extract the class label from the file path and update the\n","    # labels list\n","    label = imagePath.split(os.path.sep)[-2]\n","    labels.append(label)\n","data = np.array(data, dtype=\"float\") / 255.0\n","labels = np.array(labels)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PxwNgpFF31En"},"outputs":[],"source":["# encode the labels, converting them from strings to integers\n","lb = LabelBinarizer()\n","labels = lb.fit_transform(labels)\n"," \n","# perform a training and testing split, using 70% of the data for\n","# training and 30% for evaluation\n","(trainX, testX, trainY, testY) = train_test_split(np.array(data), np.array(labels), test_size=0.30)\n","#(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":965,"status":"ok","timestamp":1612122174503,"user":{"displayName":"Getie Balew","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnGW8p61D5iT4V8FLdNn_ApOAQSp8ES9uosL9e=s64","userId":"04202773499671067541"},"user_tz":480},"id":"b2lhgkMA31Es","outputId":"52ba316d-6399-428b-97bb-145338670a82"},"outputs":[{"name":"stdout","output_type":"stream","text":["(927, 12)\n","(2163, 128, 128, 3)\n"]}],"source":["print(testY.shape)\n","print(trainX.shape)\n","#plt.imshow(trainX[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6750,"status":"ok","timestamp":1612122213793,"user":{"displayName":"Getie Balew","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnGW8p61D5iT4V8FLdNn_ApOAQSp8ES9uosL9e=s64","userId":"04202773499671067541"},"user_tz":480},"id":"Bg2wAjCT31Ew","outputId":"d29e49cd-95dd-4b1b-b3fe-de1f53950311"},"outputs":[],"source":["# initialize the model\n","print(\"[INFO] compiling model...\")\n","#  ESLRNet, SRNet_model, ESLR_model,  AlexNet,   VGGNet, GoogLeNet,  ResNet, ESLR1, ESLR2, ESLR3\n","model =SRNet_model.build_model(width=128, height=128, depth=IMAGE_DIMS[2], classes=len(lb.classes_))\n","#model =ESLR_Net.build_model()\n","model.summary()\n","# train the model using the Adam optimizer\n","print(\"[INFO] training network...\")\n","opt = Adam(lr=1e-3, decay=1e-3 / 50)\n","model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n","    metrics=[\"accuracy\"])"]},{"cell_type":"markdown","metadata":{"id":"CxeRrLZSnVuZ"},"source":["**Data** **Augumentation**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l2hC7ynJ31E8"},"outputs":[],"source":["aug = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True, \n","                         fill_mode=\"nearest\")\n","\n","aug1 = ImageDataGenerator(\n","\trotation_range=30,\n","\tzoom_range=0.15,\n","\twidth_shift_range=0.2,\n","\theight_shift_range=0.2,\n","\tshear_range=0.15,\n","\thorizontal_flip=True,\n","\tfill_mode=\"nearest\")\n","aug2 = ImageDataGenerator(\n","\trotation_range=30, \n","\thorizontal_flip=True,\n","\tfill_mode=\"nearest\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"95nTMJ9v31FB"},"outputs":[],"source":["# train the network\n","print(\"[INFO] training network...\")\n","H = model.fit_generator(aug.flow(trainX, trainY,\n","                                 batch_size=batch_size),\n","                        validation_data=(testX, testY),\n","                        steps_per_epoch=len(trainX),\n","                        epochs=50, verbose=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":78742,"status":"ok","timestamp":1612122300180,"user":{"displayName":"Getie Balew","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnGW8p61D5iT4V8FLdNn_ApOAQSp8ES9uosL9e=s64","userId":"04202773499671067541"},"user_tz":480},"id":"zFVGczmk31FN","outputId":"87d048f0-3af4-4e73-de50-4ce4c80e09d8"},"outputs":[],"source":["print(\"[INFO] training network...\")\n","H = model.fit(trainX,trainY,\n","          batch_size=batch_size,\n","          epochs=50,\n","          validation_data=(testX, testY),\n","          shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1818,"status":"ok","timestamp":1612122377475,"user":{"displayName":"Getie Balew","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnGW8p61D5iT4V8FLdNn_ApOAQSp8ES9uosL9e=s64","userId":"04202773499671067541"},"user_tz":480},"id":"diGTUHCloYge","outputId":"e2ba9e32-04ab-4a7b-a69a-49145dd38f96"},"outputs":[],"source":["print(\"[INFO] evaluating network...\")\n","#Classes= ['class 1', 'class 2', 'class 3', 'class 4', 'class 5', 'class 6', 'class 7', 'class 8', 'class 9', 'class 10', 'class 11']\n","predictions = model.predict(testX, batch_size=batch_size)\n","print(classification_report(testY.argmax(axis=1),\n","\tpredictions.argmax(axis=1), target_names=lb.classes_))\n","\n","scores = model.evaluate(testX, testY, batch_size=batch_size, verbose=1)\n","print('\\nTest Result: %.3f loss: %.3f' % (scores[1]*100, scores[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"executionInfo":{"elapsed":1207,"status":"ok","timestamp":1612122668401,"user":{"displayName":"Getie Balew","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnGW8p61D5iT4V8FLdNn_ApOAQSp8ES9uosL9e=s64","userId":"04202773499671067541"},"user_tz":480},"id":"YkF5MqbswCay","outputId":"fd13a702-df4b-4ebd-8814-9a7b9f0e01d6"},"outputs":[],"source":["# plot the training loss and accuracy\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","N = 50\n","plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n","plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n","plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n","plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_accuracy\")\n","plt.title(\"Training Loss and Accuracy\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend(loc=\"upper left\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"executionInfo":{"elapsed":1157,"status":"ok","timestamp":1612122709741,"user":{"displayName":"Getie Balew","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnGW8p61D5iT4V8FLdNn_ApOAQSp8ES9uosL9e=s64","userId":"04202773499671067541"},"user_tz":480},"id":"U4X78WUAwC58","outputId":"3e5e3909-4e2d-400c-f355-0dd23eb24826"},"outputs":[],"source":["# summarize history for accuracy\n","plt.plot(H.history['accuracy'])\n","plt.plot(H.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"executionInfo":{"elapsed":1128,"status":"ok","timestamp":1612122729041,"user":{"displayName":"Getie Balew","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnGW8p61D5iT4V8FLdNn_ApOAQSp8ES9uosL9e=s64","userId":"04202773499671067541"},"user_tz":480},"id":"uS5nAKg2j10M","outputId":"ffd7a82f-9d62-43f8-a3bd-a2c2cbb90cc6"},"outputs":[],"source":["# summarize history for loss\n","plt.plot(H.history['loss'])\n","plt.plot(H.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2020,"status":"ok","timestamp":1608471708160,"user":{"displayName":"Getie Balew","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnGW8p61D5iT4V8FLdNn_ApOAQSp8ES9uosL9e=s64","userId":"04202773499671067541"},"user_tz":480},"id":"qx4YvdhJ31Fc","outputId":"1fe2c35e-ddbe-42fe-808e-7e8e2d5c9b34"},"outputs":[{"name":"stdout","output_type":"stream","text":["model saved to disk\n"]}],"source":["model.save('/content/drive/My Drive/Implementation steemrust/Saved_models/Steem_model.h5')\n","print('model saved to disk')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kbYN5nkV31Fg"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from keras.models import load_model\n","model = load_model('/content/drive/My Drive/Implementation steemrust/Saved_models/Steem_model.h5')\n","#image1 = '/content/drive/My Drive/Implementation steemrust/Dataset/100S/image (1).PNG'\n","#img_array =cv2.imread(image1)\n","#plt.imshow(img_array)\n","#plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"elapsed":1553,"status":"error","timestamp":1613620697230,"user":{"displayName":"Getie Balew","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnGW8p61D5iT4V8FLdNn_ApOAQSp8ES9uosL9e=s64","userId":"04202773499671067541"},"user_tz":480},"id":"7MUoESgd31Fl","outputId":"a6123002-1bb3-4c19-ee58-b257173d7804"},"outputs":[],"source":["imagePaths = paths.list_images('/content/drive/My Drive/Implementation steemrust/Dataset')\n","data = []\n","labels = []\n","# loop over our input images\n","for imagePath in imagePaths:\n","    label = imagePath.split(os.path.sep)[-2]\n","    labels.append(label)  \n","data = np.array(data, dtype=\"float\") / 255.0\n","labels = np.array(labels)\n","lb = LabelBinarizer()\n","labels = lb.fit_transform(labels)\n","\n","image_testing = cv2.imread('/content/drive/My Drive/Implementation steemrust/Dataset/40MR/image14.png')\n","image_testing = cv2.resize(image_testing, (224, 224))\n","#image_testing = img_to_array(image_testing)        \n","image_testing.shape\n","plt.imshow(image_testing)\n","plt.show()\n","image_testing = np.expand_dims(image_testing,axis=0)\n","print(image_testing.shape)\n","output = model.predict(image_testing)\n","print(output)\n","print(lb.classes_[output.argmax(axis=1)])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"elapsed":1249,"status":"error","timestamp":1608471831918,"user":{"displayName":"Getie Balew","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnGW8p61D5iT4V8FLdNn_ApOAQSp8ES9uosL9e=s64","userId":"04202773499671067541"},"user_tz":480},"id":"UneFGx8Q31Fr","outputId":"b2c713a7-81e1-4c77-c200-89db858938b0"},"outputs":[],"source":["model_json=model.to_json()\n","with open(\"Models/model.json\",'w') as json_file:\n","    json_file.write(model_json)\n","    \n","model.save_weights(\"Models/model_wal.h5\")\n","print(\"saved model to disk\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Fj6qI1y31Fw"},"outputs":[],"source":["from keras.models import model_from_json\n","json_file = open('Models/model.json', 'r')\n","loaded_model_json = json_file.read()\n","json_file.close()\n","loaded_model = model_from_json(loaded_model_json)\n","# load weights into new model\n","loaded_model.load_weights(\"Models/model_wal.h5\")\n","print(\"Loaded model from disk\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Xvx-iFT31F4"},"outputs":[],"source":["import numpy as np\n","from keras.preprocessing import image\n","test_image = image.load_img('Testing/awo.jpg', target_size = (128, 128))\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis = 0)\n","result =loaded_model.predict(test_image)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PWvwIO9o31F9"},"outputs":[],"source":["a = [[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]\n","b = [[0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]\n","c = [[0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]\n","d = [[0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]\n","e = [[0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]\n","f = [[0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]\n","g = [[0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]\n","h = [[0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]\n","i = [[0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]\n","k = [[0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]\n","l = [[0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]\n","m = [[0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]\n","n = [[0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]\n","o = [[0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]\n","p = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]\n","q = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]\n","r = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0]]\n","s = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0]]\n","t = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0]]\n","u = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0]]\n","v = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0]]\n","w = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0]]\n","x = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0]]\n","y = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0]]\n","A = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0]]\n","B = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0]]\n","C = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0]]\n","D = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0]]\n","E = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0]]\n","F = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1]]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aDq6M0OS31GB"},"outputs":[],"source":["result=result.astype (int)\n","print (result)\n","result = result.tolist()\n","print (result)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Myh71JT831GF"},"outputs":[],"source":["#training_set.class_indices\n","\n","if(result==a):\n","    label=1\n","    print (\"the gesture predicted is አዎ\")\n","\n","elif(result==b):\n","    label=2\n","    print (\"the gesture predicted is አይ \")\n","\n","elif(result==c):\n","    label=3\n","    print (\"the gesture predicted is ትምህርት ቤት \")\n","\n","elif (result==d):\n","    label=4\n","    print (\"the gesture predicted is እንጀራ \")\n","elif (result==e):\n","    label=5\n","    print (\"the gesture predicted is ጣፋጭ \")\n","elif (result==f):\n","    label=6\n","    print (\"the gesture predicted is መራራ \")\n","elif (result==g):\n","    label=7\n","    print (\"the gesture predicted is መዝናኛ \")\n","elif (result==h):\n","    label=8\n","    print (\"the gesture predicted is አውነት \")\n","elif (result==i):\n","    label=9\n","    print (\"the gesture predicted is ማመን \")\n","elif (result==k):\n","    label=10\n","    print (\"the gesture predicted is K \")\n","elif (result==l):\n","    label=11\n","    print (\"the gesture predicted is L \")\n","elif (result==m):\n","    label=12\n","    print (\"the gesture predicted is M \")\n","elif (result==n):\n","    label=13\n","    print (\"the gesture predicted is N \")\n","elif (result==o):\n","    label=14\n","    print (\"the gesture predicted is O \")\n","elif (result==p):\n","    label=15\n","    print (\"the gesture predicted is P \")\n","elif (result==q):\n","    label=16\n","    print (\"the gesture predicted is Q \")\n","elif (result==r):\n","    label=17\n","    print (\"the gesture predicted is R \")\n","elif (result==s):\n","    label=18\n","    print (\"the gesture predicted is S \")\n","elif (result==t):\n","    label=19\n","    print (\"the gesture predicted is T \")\n","elif (result==u):\n","    label=20\n","    print (\"the gesture predicted is U \")\n","elif (result==v):\n","    label=21\n","    print (\"the gesture predicted is V \")\n","elif (result==w):\n","    label=22\n","    print (\"the gesture predicted is W \")\n","elif (result==x):\n","    label=23\n","    print (\"the gesture predicted is X \")\n","elif (result==y):\n","    label=24\n","    print (\"the gesture predicted is Y \")\n","    \n","else:\n","    print(\"No image predicted\")\n","    \n","print (\"Label of the gesture is\",label)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wOFexqUs31GK"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3LHjQIDf31GN"},"outputs":[],"source":["# extract and plot each detected face in a photograph\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.patches import Rectangle\n","from matplotlib.patches import Circle\n","from mtcnn.mtcnn import MTCNN\n","import cv2\n","y1=0\n","x1=0\n","width=0\n","height=0\n","x2=0\n","y2=0\n","class Segment_face():\n","    def face_Segment(img):\n","        detector = MTCNN()\n","        # detect faces in the image\n","        faces = detector.detect_faces(img)\n","        #print(len(faces))\n","        for i in range(len(faces)):\n","            # get coordinates\n","            x1, y1, width, height = faces[i]['box']\n","            x2, y2 = x1 + width, y1 + height\n","        img=img[y1:y2, x1:x2]\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","        print('success')\n","        return img\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ZT3mq2LqG1Fa"},"source":["Face Segmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qkZwyHpW31GX"},"outputs":[],"source":["import cv2\n","from cv2 import destroyAllWindows\n","from cv2 import CascadeClassifier\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.patches import Rectangle\n","from matplotlib.patches import Circle\n","class Segment_face():\n","    def face_Segment(img):\n","\n","      detector = CascadeClassifier('/content/drive/My Drive/Dataset/haarcascade_frontalface_default.xml')\n","      # perform face detection\n","      faces = detector.detectMultiScale(img)\n","      for i in range(len(faces)):\n","        # get coordinates\n","        x1, y1, width, height = faces[i]\n","        x2, y2 = x1 + width, y1 + height\n","      data=img[y1:y2, x1:x2]\n","      gray = cv2.cvtColor(data, cv2.COLOR_BGR2GRAY)\n","      print('success')\n","      return img"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IPi4tZug31Gc"},"outputs":[],"source":["print(\"[INFO] loading images...\")\n","\n","f_imagePaths = paths.list_images('/content/drive/My Drive/Dataset/Facial_Dataset')\n","f_data = []\n","f_labels = []\n","\n","# loop over our input images\n","for f_imagePath in f_imagePaths:\n","    # load the image, pre-process it, and store it in the data list\n","    # load the input image from disk, resize it to 200x200 pixels, scale\n","    # the pixel intensities to the range [0, 1], and then update our\n","    # images list\n","    f_image = cv2.imread(f_imagePath)\n","    #image = cv2.resize(image, (224,224))\n","    f_image = cv2.resize(f_image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n","    #f_image = Segment_face.face_Segment(f_image)\n","    #print(f_imagePath)\n","    #plt.imshow(image)\n","    #f_image=cv2.resize(image,(48,48)\n","    f_image = img_to_array(f_image)        \n","    f_data.append(f_image)\n","     \n","    # extract the class label from the file path and update the\n","    # labels list\n","    f_label = f_imagePath.split(os.path.sep)[-2]\n","    f_labels.append(f_label)\n","    \n","f_data = np.array(f_data, dtype=\"float\") / 255.0\n","f_labels = np.array(f_labels)\n","    \n","#plt.imshow(image)\n","\n","#cv2.imshow('Image.jpg',image)\n","#cv2.waitKey()\n","#cv2.destroyAllWindows(0)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yF751G5A31Gg"},"outputs":[],"source":["# encode the labels, converting them from strings to integers\n","f_lb = LabelBinarizer()\n","f_labels = f_lb.fit_transform(f_labels)\n","\n","# perform a training and testing split, using 75% of the data for\n","# training and 25% for evaluation\n","(f_trainX, f_testX, f_trainY, f_testY) = train_test_split(np.array(f_data),\n","\tnp.array(f_labels), test_size=0.25)\n","#(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MeCbxMlL31Gk"},"outputs":[],"source":["print(f_trainX.shape)\n","print(f_trainY.shape)\n","plt.imshow(f_trainX[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KrX9DXFk31Gn"},"outputs":[],"source":["# initialize the model\n","print(\"[INFO] compiling model...\")\n","f_model = model_bel.build_model(width=128, height=128,\n","    depth=IMAGE_DIMS[2], classes=len(f_lb.classes_))\n","f_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zpPbTAtV31Gt"},"outputs":[],"source":["# train the model using the Adam optimizer\n","print(\"[INFO] training network...\")\n","f_opt = Adam(lr=1e-3, decay=1e-3 / 50)\n","f_model.compile(loss=\"categorical_crossentropy\", optimizer=f_opt,\n","    metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9WNZExIQ31Gx"},"outputs":[],"source":["f_H = f_model.fit(f_trainX,f_trainY,\n","          batch_size=batch_size,\n","          epochs=num_epoch,\n","          validation_data=(f_testX, f_testY),\n","          shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pTiPwdj031G1"},"outputs":[],"source":["# evaluate the network\n","print(\"[INFO] evaluating network...\")\n","f_predictions = f_model.predict(f_testX, batch_size=batch_size)\n","print(classification_report(f_testY.argmax(axis=1),\n","\tf_predictions.argmax(axis=1), target_names=f_lb.classes_))\n","\n","f_scores = f_model.evaluate(f_testX, f_testY, batch_size=batch_size, verbose=1)\n","print('\\nTest Result: %.3f loss: %.3f' % (f_scores[1]*100, f_scores[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pup9xpcy31G4"},"outputs":[],"source":["# plot the training loss and accuracy\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","N = num_epoch\n","plt.plot(np.arange(0, N), f_H.history[\"loss\"], label=\"train_loss\")\n","plt.plot(np.arange(0, N), f_H.history[\"val_loss\"], label=\"val_loss\")\n","plt.plot(np.arange(0, N), f_H.history[\"accuracy\"], label=\"train_acc\")\n","plt.plot(np.arange(0, N), f_H.history[\"val_accuracy\"], label=\"val_accuracy\")\n","plt.title(\"Training Loss and Accuracy\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend(loc=\"upper left\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kqpJM0kRmAv9"},"outputs":[],"source":["# ResNet trained on image size ?(224, 224)\n","# import the necessary packages\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.convolutional import AveragePooling2D\n","from keras.layers.convolutional import ZeroPadding2D\n","from keras.layers.core import Activation\n","from keras.layers.core import Dense\n","from keras.layers import Flatten\n","from keras.layers import Input\n","from keras.models import Model\n","from keras.layers import add\n","from keras.regularizers import l2\n","from keras import backend as K\n","\n","class ResNet:\n","\t@staticmethod\n","\tdef resid_module(data, K, stride, chanDim, red=False, reg=0.0001, bnEps=2e-5, bnMom=0.9):\n","\t\t# the shortcut branch of the ResNet module should be \n","\t\t# initialized as the input (identity) data\n","\t\tshortcut = data\n","\n","\t\t# the first block of the ResNet module are the 1x1 CONVs\n","\t\tbn1 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(data)\n","\t\tact1 = Activation(\"relu\")(bn1)\n","\t\tconv1 = Conv2D(int(K*0.25), (1,1), use_bias=False, kernel_regularizer=l2(reg))(act1)\n","\n","\t\t# the second block of the ResNet module are the 3x3 CONVs\n","\t\tbn2 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(conv1)\n","\t\tact2 = Activation(\"relu\")(bn2)\n","\t\tconv2 = Conv2D(int(K*0.25), (3,3), strides=stride, padding=\"same\", use_bias=False, kernel_regularizer=l2(reg))(act2)\n","\n","\t\t# the third block of the ResNet module(another set of 1x1 CONVs)\n","\t\tbn3 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(conv2)\n","\t\tact3 = Activation(\"relu\")(bn3)\n","\t\tconv3 = Conv2D(K, (1,1), use_bias=False, kernel_regularizer=l2(reg))(act3)\n","\n","\t\t# if we are to reduce the spatial size,\n","\t\t# apply a CONV layer to the shortcut\n","\t\tif red:\n","\t\t\tshortcut = Conv2D(K, (1,1), strides=stride, use_bias=False, kernel_regularizer=l2(reg))(act1)\n","\n","\t\t# add shortcut and the final CONV\n","\t\tx = add([conv3, shortcut])\n","\n","\t\t# return the addition as the output of the ResNet module\n","\t\treturn x\n","\n","\t@staticmethod\n","\tdef build_model(width, height, depth, classes, stages=(3,4,6), filters=(64,128,256,512), reg=0.0001, bnEps=2e-5, bnMom=0.9):\n","\t\t# initialize the input shape to be \"channels last\" and \n","\t\t# the channels dimension itself\n","\t\tinputShape = (height, width, depth)\n","\t\tchanDim = -1\n","\n","\t\t# if channels first, update the input shape and channel dim\n","\t\tif K.image_data_format() == \"channels_first\":\n","\t\t\tinputShape = (depth, height, width)\n","\t\t\tchanDim = 1\n","\n","\t\t# set the input and apply BN\n","\t\tinputs = Input(shape=inputShape)\n","\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(inputs)\n","\n","\t\t''' for cifar-10 dataset\n","\t\tx = Conv2D(filters[0], (3, 3), use_bias=False, padding=\"same\", kernel_regularizer=l2(reg))(x)\n","\t\t'''\n","\n","\t\t# for Image Dataset\n","\t\t# CONV => BN => ACT => POOL \n","\t\tx = Conv2D(filters[0], (5, 5), use_bias=False, padding=\"same\", kernel_regularizer=l2(reg))(x)\n","\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n","\t\tx = Activation(\"relu\")(x)\n","\t\tx = ZeroPadding2D((1, 1))(x)\n","\t\tx = MaxPooling2D((3, 3), strides=(2,2))(x)\n","\n","\t\t# loop over the number of stages\n","\t\tfor i in range(0, len(stages)):\n","\t\t\t# initialize the stride, then apply a residual module\n","\t\t\t# used to reduce the spatial size of the input volume\n","\t\t\tstride = (1,1) if i == 0 else (2,2)\n","\t\t\tx = ResNet.resid_module(x, filters[i+1], stride, chanDim, red=True, bnEps=bnEps, bnMom=bnMom)\n","\n","\t\t\t# loop over the number of layers in the stage\n","\t\t\tfor j in range(0, stages[i] - 1):\n","\t\t\t\t# apply a ResNet module\n","\t\t\t\tx = ResNet.resid_module(x, filters[i+1], (1,1), chanDim, bnEps=bnEps, bnMom=bnMom)\n","\n","\t\t# apply BN => ACT => POOL\n","\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n","\t\tx = Activation(\"relu\")(x)\n","\t\tx = AveragePooling2D(5,5)(x)\n","\n","\t\t# softmax classifier\n","\t\tx = Flatten()(x)\n","\t\tx = Dense(classes, kernel_regularizer=l2(reg))(x)\n","\t\tx = Activation(\"softmax\")(x)\n","\n","\t\t# create the model\n","\t\tmodel = Model(inputs, x)\n","\n","\t\t# return the constructed network architectures\n","\t\treturn model"]},{"cell_type":"markdown","metadata":{"id":"lHWy3qFFHHGo"},"source":["Skinn segment"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1316,"status":"ok","timestamp":1608472221533,"user":{"displayName":"Getie Balew","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnGW8p61D5iT4V8FLdNn_ApOAQSp8ES9uosL9e=s64","userId":"04202773499671067541"},"user_tz":480},"id":"7LwgcV0_31G-","outputId":"5fb31fad-177d-4df6-837d-0c9a0bcf8406"},"outputs":[{"name":"stdout","output_type":"stream","text":["success\n"]}],"source":["import cv2\n","import numpy as np\n","class Segment_skin():\n","    def skin_Segment(img):\n","\n","        img_YCrCb = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB)\n","        YCrCb_mask = cv2.inRange(img_YCrCb, (0, 135, 85), (255,180,135)) \n","        YCrCb_mask = cv2.morphologyEx(YCrCb_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n","    \n","        YCrCb_result = cv2.bitwise_not(YCrCb_mask)\n","    \n","        img2=img\n","        for i in range(img2.shape[0]):\n","            for j in range(img2.shape[1]):\n","                if YCrCb_result[i,j] != 0:\n","                    img2[i,j,0] = 0\n","                    img2[i,j,1] = 0\n","                    img2[i,j,2] = 0\n","    \n","        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n","        YCrCb_mask = cv2.erode(YCrCb_mask, kernel, iterations = 2)\n","        YCrCb_mask = cv2.dilate(YCrCb_mask, kernel, iterations = 2)\n","        print('sucess')\n","        return img2\n","        #return YCrCb_result\n","print('success')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8198,"status":"ok","timestamp":1612110108043,"user":{"displayName":"Getie Balew","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnGW8p61D5iT4V8FLdNn_ApOAQSp8ES9uosL9e=s64","userId":"04202773499671067541"},"user_tz":480},"id":"dZViWAME31HD","outputId":"92e22849-309d-4d49-e577-d6e3d44b19ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["sucess\n"]}],"source":["# GoogLeNet - 16 trained on image size (224, 224)\n","# import the necessary packages\n","from keras.models import Sequential\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import AveragePooling2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.core import Activation\n","from keras.layers.core import Flatten\n","from keras.layers.core import Dropout\n","from keras.layers.core import Dense\n","from keras.layers import Input\n","from keras.models import Model\n","from keras.layers import concatenate\n","from keras.regularizers import l2\n","from keras import backend as K\n","\n","class GoogLeNet:\n","\t@staticmethod\n","\tdef conv_module(x, K, kX, kY, stride, chanDim, padding=\"same\", reg=0.0005):\n","\t\t#initialize the CONV, BN, and RELU layer names\n","\n","\t\t# define a CONV => BN => RELU pattern\n","\t\tx = Conv2D(K, (kX, kY), strides=stride, padding=padding, kernel_regularizer=l2(reg))(x)\n","\t\tx = BatchNormalization(axis=chanDim)(x)\n","\t\tx = Activation(\"relu\")(x)\n","\n","\t\t# return the block\n","\t\treturn x\n","\n","\t@staticmethod\n","\tdef inception_mod(x, num1x1, num3x3Reduce, num3x3, num5x5Reduce, num5x5, num1x1Proj, chanDim, reg=0.0005):\n","\t\t# define the first branch of the Inception module consisting\n","\t\t# of 1 x 1 convolutions\n","\t\tfirst = GoogLeNet.conv_module(x, num1x1, 1, 1, (1,1), chanDim, reg=reg)\n","\t\t# define the second branch of the Inception module consisting\n","\t\t# of 1 x 1 and 3 x 3 convolutions\n","\t\tsecond = GoogLeNet.conv_module(x, num3x3Reduce, 1, 1, (1,1), chanDim, reg=reg)\n","\t\tsecond = GoogLeNet.conv_module(second, num3x3, 3, 3, (1,1), chanDim, reg=reg)\n","\t\t# define the third branch of the Inception module consisting\n","\t\t# of 1 x 1 and 5 x 5 convolutions\n","\t\tthird = GoogLeNet.conv_module(x, num5x5Reduce, 1, 1, (1,1), chanDim, reg=reg)\n","\t\tthird = GoogLeNet.conv_module(third, num5x5, 5, 5, (1,1), chanDim, reg=reg)\n","\t\t# define the fourth branch of the Inception module consisting\n","\t\t# of the POOLing projection\n","\t\tfourth = MaxPooling2D((3,3), strides=(1,1), padding=\"same\")(x)\n","\t\tfourth = GoogLeNet.conv_module(fourth, num1x1Proj, 1, 1, (1,1), chanDim, reg=reg)\n","\n","\t\tx = concatenate([first, second, third, fourth], axis = chanDim)\n","\n","\t\t# return the block\n","\t\treturn x\n","\n","\t@staticmethod\n","\tdef build_model(width, height, depth, classes, reg=0.0005):\n","\t\t# initialize the model along with the input shape to be\n","\t\t# \"channels last\" and the channels dimension itself\n","\t\t# model = Sequential()\n","\t\tinputShape = (height, width, depth)\n","\t\tchanDim = -1\n","\n","\t\t# if we are using \"channels first\", update the input shape\n","\t\t# and channels dimension\n","\t\tif K.image_data_format() == \"channels_first\":\n","\t\t\tinputShape = (depth, height, width)\n","\t\t\tchanDim = 1\n","\n","\t\t# define the model input and first CONV module\n","\t\tinputs = Input(shape=inputShape)\n","\t\t# CONV => POOL => (CONV * 2) => POOL\n","\t\tx = GoogLeNet.conv_module(inputs, 64, 7, 7, (2,2), chanDim, reg=reg)\n","\t\t# POOL1\n","\t\tx = MaxPooling2D((3,3),strides=(2,2), padding=\"same\")(x)\n","\t\t# two CONV module (the original paper contains only 1 CONV)\n","\t\tx = GoogLeNet.conv_module(x, 192, 3, 3, (1,1), chanDim, reg=reg)\n","\t\t\n","\t\t# POOL2\t\t\n","\t\tx = MaxPooling2D((3,3), strides=(2,2), padding=\"same\")(x)\n","\n","\t\t# the two inception modules\n","\t\tx = GoogLeNet.inception_mod(x, 64, 96, 128, 16, 32, 32, chanDim, reg=reg)\n","\t\tx = GoogLeNet.inception_mod(x, 128, 128, 192, 32, 96, 64, chanDim, reg=reg)\n","\n","\t\t# POOL3\n","\t\tx = MaxPooling2D((3,3), strides=(2,2), padding=\"same\")(x)\n","\n","\t\t# the five inception modules\n","\t\tx = GoogLeNet.inception_mod(x, 192, 96, 208, 16, 48, 64, chanDim, reg=reg)\n","\t\tx = GoogLeNet.inception_mod(x, 160, 112, 224, 24, 64, 64, chanDim, reg=reg)\n","\t\tx = GoogLeNet.inception_mod(x, 128, 128, 256, 24, 64, 64, chanDim, reg=reg)\n","\t\tx = GoogLeNet.inception_mod(x, 112, 144, 288, 32, 64, 64, chanDim, reg=reg)\n","\t\tx = GoogLeNet.inception_mod(x, 256, 160, 320, 32, 128, 128, chanDim, reg=reg)\n","\n","\t\t# POOL4\n","\t\tx = MaxPooling2D((3,3), strides=(2,2), padding=\"same\")(x)\n","\t\t\n","\t\t# the two inception modules\n","\t\tx = GoogLeNet.inception_mod(x, 256, 160, 320, 32, 128, 128, chanDim, reg=reg)\n","\t\tx = GoogLeNet.inception_mod(x, 384, 192, 384, 48, 128, 128, chanDim, reg=reg)\n","\n","\n","\n","\t\t# AVG POOL => DO\n","\t\tx = AveragePooling2D((7,7))(x)\n","\t\tx = Dropout(0.4)(x)\n","\t\t\n","\n","\t\t# flatten , softmax\n","\t\tx = Flatten()(x)\n","\t\tx = Dense(classes, kernel_regularizer=l2(reg))(x)\n","\t\tx = Activation(\"softmax\")(x)\n","\n","\t\t# create the model\n","\t\tmodel = Model(inputs, x, name=\"GoogLeNet\")\n","\t\t# return the constructed network architecture\n","\t\treturn model\n","print('sucess')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q4Ewsd91XZKj"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, AveragePooling2D\n","from keras import backend as K\n","class SRNet_model:\n","    @staticmethod\n","    def build_model(width, height, depth, classes):\n","        # initialize the model along with the input shape to be\n","        # \"channels last\" and the channels dimension itself\n","        model = Sequential()\n","        inputShape = (height, width, depth)\n","        chanDim = -1\n","        if K.image_data_format() == \"channels_first\":\n","            inputShape = (depth, height, width)\n","            chanDim = 1\n","        model.add(Conv2D(32, (5, 5), padding=\"same\", strides=(2,2),\n","                         input_shape=inputShape))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\t\t\n","        model.add(Conv2D(32, (3, 3), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Conv2D(32, (5, 5), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Conv2D(32, (3, 3), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n","        model.add(Dropout(0.25))\n","        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))    \n","        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n","        model.add(Dropout(0.25))\n","        model.add(Conv2D(128, (3, 3), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Conv2D(128, (1, 1), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","\t\t#model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","        model.add(Conv2D(128, (3, 3), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Conv2D(128, (1, 1), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(MaxPooling2D(pool_size=(2, 2)))\n","        model.add(Dropout(0.25))\n","\t\t\n","\t\t# first (and only) set of FC => RELU layers\n","        model.add(Flatten())\n","        model.add(Dense(1024))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Dropout(0.5))\n","\n","\t\t# softmax classifier\n","        model.add(Dense(12))\n","        model.add(Activation(\"softmax\"))\n","\n","\t\t# return the constructed network architecture\n","        return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V6Uwd6T4XZun"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, AveragePooling2D\n","from keras import backend as K\n","\n","\n","class ESLR_model:\n","    @staticmethod\n","    def build_model(width, height, depth, classes):\n","        # initialize the model along with the input shape to be\n","        # \"channels last\" and the channels dimension itself\n","        model = Sequential()\n","        inputShape = (height, width, depth)\n","        chanDim = -1\n","\n","\t\t# if we are using \"channels first\", update the input shape\n","\t\t# and channels dimension\n","        if K.image_data_format() == \"channels_first\":\n","            inputShape = (depth, height, width)\n","            chanDim = 1\n","\n","\t\t# (CONV => RELU => CONV => RELU ) * 2 => POOL\n","        model.add(Conv2D(32, (5, 5), padding=\"same\", strides=(2,2),\n","                         input_shape=inputShape))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\t\t\n","        model.add(Conv2D(32, (3, 3), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        #model.add(MaxPooling2D(pool_size=(3, 3),strides=(2,2)))\n","\n","        model.add(Conv2D(32, (5, 5), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Conv2D(32, (3, 3), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n","        model.add(Dropout(0.25))\n","\n","\t\t# (CONV => RELU => CONV => RELU) * 2  => POOL\n","        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        #model.add(MaxPooling2D(pool_size=(2, 2)))\n","        \n","        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n","        model.add(Dropout(0.25))\n","        # (CONV => RELU => CONV => RELU) * 2 => POOL\n","        model.add(Conv2D(128, (3, 3), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Conv2D(128, (1, 1), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","\t\t#model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","        model.add(Conv2D(128, (3, 3), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Conv2D(128, (1, 1), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(MaxPooling2D(pool_size=(2, 2)))\n","        model.add(Dropout(0.25))\n","\t\t\n","\t\t# first (and only) set of FC => RELU layers\n","        model.add(Flatten())\n","        model.add(Dense(1024))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Dropout(0.5))\n","\n","\t\t# softmax classifier\n","        model.add(Dense(12))\n","        model.add(Activation(\"softmax\"))\n","\n","\t\t# return the constructed network architecture\n","        return model\n","\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Z3R8bg3kPRx"},"outputs":[],"source":["# VGGNet - 16 trained on image size (224, 224)\n","# import the necessary packages\n","from keras.models import Sequential\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.core import Activation\n","from keras.layers.core import Flatten\n","from keras.layers.core import Dropout\n","from keras.layers.core import Dense\n","from keras import backend as K\n","\n","class VGGNet:\n","\t@staticmethod\n","\tdef build_model(width, height, depth, classes):\n","\t\t# initialize the model along with the input shape to be\n","\t\t# \"channels last\" and the channels dimension itself\n","\t\tmodel = Sequential()\n","\t\tinputShape = (height, width, depth)\n","\t\tchanDim = -1\n","\n","\t\t# if we are using \"channels first\", update the input shape\n","\t\t# and channels dimension\n","\t\tif K.image_data_format() == \"channels_first\":\n","\t\t\tinputShape = (depth, height, width)\n","\t\t\tchanDim = 1\n","\n","\n","\t\t# (CONV => RELU => BN) * 2 => POOL => DO\n","\t\tmodel.add(Conv2D(64, (3,3), padding=\"same\", strides=(1,1), input_shape=inputShape))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Conv2D(64, (3,3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n","\t\tmodel.add(Dropout(0.25))\n","\n","\t\t# (CONV => RELU => BN) * 2 => POOL => DO\n","\t\tmodel.add(Conv2D(128, (3,3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Conv2D(128, (3,3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n","\t\tmodel.add(Dropout(0.25))\n","\n","\t\t# (CONV => RELU => BN) * 3 => POOL => DO\n","\t\tmodel.add(Conv2D(256, (3,3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Conv2D(256, (3,3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Conv2D(256, (3,3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n","\t\tmodel.add(Dropout(0.25))\n","\n","\t\t# (CONV => RELU => BN) * 3 => POOL\n","\t\tmodel.add(Conv2D(512, (3,3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Conv2D(512, (3,3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Conv2D(512, (3,3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n","\t\tmodel.add(Dropout(0.25))\n","\n","\t\t# (CONV => RELU => BN) * 3 => POOL\n","\t\tmodel.add(Conv2D(512, (3,3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Conv2D(512, (3,3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Conv2D(512, (3,3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n","\t\tmodel.add(Dropout(0.25))\n","\n","\t\t# \n","\t\tmodel.add(Flatten())\n","\t\tmodel.add(Dense(4096))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Dropout(0.5))\n","\n","\t\tmodel.add(Dense(4096))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Dropout(0.5))\n","\n","\t\tmodel.add(Dense(12))\n","\t\tmodel.add(Activation(\"softmax\"))\n","\n","\t\t# return the constructed network architecture\n","\t\treturn model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UGVLFfRXkSSD"},"outputs":[],"source":["# import the necessary packages\n","from keras.models import Sequential\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.core import Activation\n","from keras.layers.core import Flatten\n","from keras.layers.core import Dropout\n","from keras.layers.core import Dense\n","from keras import backend as K\n","\n","class AlexNet:\n","\t@staticmethod\n","\tdef build_model(width, height, depth, classes):\n","\t\t# initialize the model along with the input shape to be\n","\t\t# \"channels last\" and the channels dimension itself\n","\t\tmodel = Sequential()\n","\t\tinputShape = (height, width, depth)\n","\t\tchanDim = -1\n","\n","\t\t# if we are using \"channels first\", update the input shape\n","\t\t# and channels dimension\n","\t\tif K.image_data_format() == \"channels_first\":\n","\t\t\tinputShape = (depth, height, width)\n","\t\t\tchanDim = 1\n","\n","\t\t# layer 1\n","\t\tmodel.add(Conv2D(96, (11, 11), padding=\"same\", strides=(4,4), input_shape=inputShape))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n","\n","\t\t# layer 2\n","\t\tmodel.add(Conv2D(256, (5,5), padding=\"same\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Activation(\"relu\"))\t\t\n","\t\tmodel.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n","\n","\t\t# layer 3\n","\t\tmodel.add(Conv2D(384, (3,3), padding=\"same\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\t# layer 4\n","\t\tmodel.add(Conv2D(384, (3,3), padding=\"same\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\t# layer 5\n","\t\tmodel.add(Conv2D(256, (3,3), padding=\"same\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n","\t\t#model.add(Dropout(0.25))\n","\n","\t\t# layer 6\n","\t\tmodel.add(Flatten())\n","\t\tmodel.add(Dense(4096))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(Dropout(0.5))\n","\n","\t\t# layer 7\n","\t\tmodel.add(Dense(4096))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(Dropout(0.5))\n","\n","\t\t#layer 8\n","\t\tmodel.add(Dense(12))\n","\t\tmodel.add(Activation(\"softmax\"))\n","\n","\t\t# return the constructed network architecture\n","\t\treturn model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wfZgL6spkdf0"},"outputs":[],"source":["# import the necessary packages\n","from keras.models import Sequential\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.core import Activation\n","from keras.layers.core import Flatten\n","from keras.layers.core import Dropout\n","from keras.layers.core import Dense\n","from keras import backend as K\n","\n","class ESLR_Net1:\n","\t@staticmethod\n","\tdef build_model(width, height, depth, classes):\n","\t\t# initialize the model along with the input shape to be\n","\t\t# \"channels last\" and the channels dimension itself\n","\t\tmodel = Sequential()\n","\t\tinputShape = (height, width, depth)\n","\t\tchanDim = -1\n","\n","\t\t# if we are using \"channels first\", update the input shape\n","\t\t# and channels dimension\n","\t\tif K.image_data_format() == \"channels_first\":\n","\t\t\tinputShape = (depth, height, width)\n","\t\t\tchanDim = 1\n","\n","\t\t# (CONV => RELU => CONV => RELU ) * 2 => POOL\n","\t\tmodel.add(Conv2D(32, (5, 5), padding=\"same\", strides=(2,2),\n","\t\t\tinput_shape=inputShape))\n","\t\tmodel.add(Activation(\"relu\"))\t\n","\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\t#model.add(MaxPooling2D(pool_size=(3, 3)))\n","\t\t\n","\t\tmodel.add(Conv2D(32, (5, 5), padding=\"same\", strides=(2,2)))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n","\t\t\n","\n","\t\t# (CONV => RELU => CONV => RELU) * 2  => POOL\n","\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\t#model.add(MaxPooling2D(pool_size=(2, 2)))\n","\t\t\n","\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n","\t\t\n","\t\t# (CONV => RELU => CONV => RELU) * 2 => POOL\n","\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\", strides=(2,2)))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(Conv2D(128, (1, 1), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\t#model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\", strides=(2,2)))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(Conv2D(128, (1, 1), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n","\t\t\n","\t\t\n","\t\t# first (and only) set of FC => RELU layers\n","\t\tmodel.add(Flatten())\n","\t\tmodel.add(Dense(1024))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(Dropout(0.5))\n","\n","\t\t# softmax classifier\n","\t\tmodel.add(Dense(12))\n","\t\tmodel.add(Activation(\"softmax\"))\n","\n","\t\t# return the constructed network architecture\n","\t\treturn model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t6-GPAuZnQ2B"},"outputs":[],"source":["# import the necessary packages\n","'''\n","from keras.models import Sequential\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.core import Activation\n","from keras.layers.core import Flatten\n","from keras.layers.core import Dropout\n","from keras.layers.core import Dense\n","from keras import backend as K\n","'''\n","import tensorflow as tf\n","\n","class ESLR_Net2:\n","\t@staticmethod\n","\tdef build_model(width, height, depth, classes):\n","\t\t# initialize the model along with the input shape to be\n","\t\t# \"channels last\" and the channels dimension itself\n","\t\tinputShape = (height, width, depth)\n","\t\tchanDim = -1\n","\n","\t\t# define the model input\n","\t\tinputs = tf.keras.layers.Input(shape=inputShape)\n","\n","\t\t# (CONV => RELU => CONV => RELU ) * 2 => POOL\n","\t\tx = tf.keras.layers.Conv2D(32, (5, 5), padding=\"same\", strides=(2,2))(inputs)\n","\t\tx = tf.keras.layers.Activation(\"relu\")(x)\n","\t\tx = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\t\t\n","\t\tx = tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\")(x)\n","\t\tx = tf.keras.layers.Lambda(lambda t: tf.nn.crelu(x))(x)\n","\t\tx = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n","\t\t#model.add(MaxPooling2D(pool_size=(3, 3)))\n","\t\t\n","\t\tx = tf.keras.layers.Conv2D(32, (5, 5), padding=\"same\", strides=(2,2))(x)\n","\t\tx = tf.keras.layers.Lambda(lambda t: tf.nn.crelu(x))(x)\n","\t\tx = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n","\t\tx = tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\")(x)\n","\t\tx = tf.keras.layers.Lambda(lambda t: tf.nn.crelu(x))(x)\n","\t\tx = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n","\t\tx = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2,2))(x)\n","\t\tx = tf.keras.layers.Dropout(0.25)(x)\n","\n","\t\t# (CONV => RELU => CONV => RELU) * 2  => POOL\n","\t\tx = tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\")(x)\n","\t\tx = tf.keras.layers.Lambda(lambda t: tf.nn.crelu(x))(x)\n","\t\tx = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n","\t\tx = tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\")(x)\n","\t\tx = tf.keras.layers.Lambda(lambda t: tf.nn.crelu(x))(x)\n","\t\tx = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n","\t\t#model.add(MaxPooling2D(pool_size=(2, 2)))\n","\t\t\n","\t\tx = tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\")(x)\n","\t\tx = tf.keras.layers.Lambda(lambda t: tf.nn.crelu(x))(x)\n","\t\tx = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n","\t\tx = tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\")(x)\n","\t\tx = tf.keras.layers.Lambda(lambda t: tf.nn.crelu(x))(x)\n","\t\tx = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n","\t\tx = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2))(x)\n","\t\tx = tf.keras.layers.Dropout(0.25)(x)\n","\t\t# (CONV => RELU => CONV => RELU) * 2 => POOL\n","\t\tx = tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", strides=(2,2))(x)\n","\t\tx = tf.keras.layers.Lambda(lambda t: tf.nn.crelu(x))(x)\n","\t\tx = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n","\t\tx = tf.keras.layers.Conv2D(128, (1, 1), padding=\"same\")(x)\n","\t\tx = tf.keras.layers.Lambda(lambda t: tf.nn.crelu(x))(x)\n","\t\tx = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n","\t\t#model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","\t\tx = tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", strides=(2,2))(x)\n","\t\tx = tf.keras.layers.Lambda(lambda t: tf.nn.crelu(x))(x)\n","\t\tx = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n","\t\tx = tf.keras.layers.Conv2D(128, (1, 1), padding=\"same\")(x)\n","\t\tx = tf.keras.layers.Lambda(lambda t: tf.nn.crelu(x))(x)\n","\t\tx = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n","\t\tx = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n","\t\tx = tf.keras.layers.Dropout(0.25)(x)\n","\t\t\n","\t\t# first (and only) set of FC => RELU layers\n","\t\tx = tf.keras.layers.Flatten()(x)\n","\t\tx = tf.keras.layers.Dense(1024)(x)\n","\t\tx = tf.keras.layers.Lambda(lambda t: tf.nn.crelu(x))(x)\n","\t\tx = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n","\t\tx = tf.keras.layers.Dropout(0.5)(x)\n","\n","\t\t# softmax classifier\n","\t\tx = tf.keras.layers.Dense(12)(x)\n","\t\tx = tf.keras.layers.Activation(\"softmax\")(x)\n","\n","\t\t# create the model\n","\t\tmodel = tf.keras.models.Model(inputs, x)\n","\n","\t\t# return the constructed network architecture\n","\t\treturn model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wxkbr-FvnRJy"},"outputs":[],"source":["# TDGPerNet - 16 trained on image size (224, 224)\n","# import the necessary packages\n","from keras.models import Sequential\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import AveragePooling2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.core import Activation\n","from keras.layers.core import Flatten\n","from keras.layers.core import Dropout\n","from keras.layers.core import Dense\n","from keras.layers import Input\n","from keras.models import Model\n","from keras.layers import concatenate\n","from keras.regularizers import l2\n","from keras import backend as K\n","\n","class ESLR_Net3:\n","\t@staticmethod\n","\tdef conv_module(x, K, kX, kY, stride, chanDim, padding=\"same\", reg=0.0005):\n","\t\t#initialize the CONV, BN, and RELU layer names\n","\n","\t\t# define a CONV => BN => RELU pattern\n","\t\tx = Conv2D(K, (kX, kY), strides=stride, padding=padding, kernel_regularizer=l2(reg))(x)\n","\t\tx = Activation(\"relu\")(x)\n","\t\tx = BatchNormalization(axis=chanDim)(x)\n","\t\t\n","\t\t# return the block\n","\t\treturn x\n","\n","\t@staticmethod\n","\tdef pool_mod(x, psize, stride, dropout=0.1):\n","\t\tmaxim = MaxPooling2D(pool_size=psize,strides=stride)(x)\n","\t\tavrg = AveragePooling2D(pool_size=psize, strides=stride)(x)\n","\n","\t\t# concatenate maxpooling and averagepooling\n","\t\tx = concatenate([maxim, avrg])\n","\t\tx = Dropout(dropout)(x)\n","\t\t# return the block\n","\t\treturn x\n","\n","\t@staticmethod\n","\tdef inception_mod(x, num1x1, num3x3, num5x5, chanDim, reg=0.0005):\n","\t\t# define the first branch of the Inception module consisting\n","\t\t# of 1 x 1 convolutions\n","\t\tfirst = ESLR_Net3.conv_module(x, num1x1, 1, 1, (1,1), chanDim, reg=reg)\n","\t\t# define the second branch of the Inception module consisting\n","\t\t# of 1 x 1 and 3 x 3 convolutions\n","\t\t#second = TDGPerNet.conv_module(x, num3x3Reduce, 1, 1, (1,1), chanDim, reg=reg)\n","\t\tsecond = ESLR_Net3.conv_module(x, num3x3, 3, 3, (1,1), chanDim, reg=reg)\n","\t\t# define the third branch of the Inception module consisting\n","\t\t# of 1 x 1 and 5 x 5 convolutions\n","\t\t#third = TDGPerNet.conv_module(x, num5x5Reduce, 1, 1, (1,1), chanDim, reg=reg)\n","\t\tthird = ESLR_Net3.conv_module(x, num5x5, 5, 5, (1,1), chanDim, reg=reg)\n","\n","\t\tx = concatenate([first, second, third], axis = chanDim)\n","\n","\t\t# return the block\n","\t\treturn x\n","\n","\t@staticmethod\n","\tdef build_model(width, height, depth, classes, reg=0.0005):\n","\t\t# initialize the model along with the input shape to be\n","\t\t# \"channels last\" and the channels dimension itself\n","\t\t# model = Sequential()\n","\t\tinputShape = (height, width, depth)\n","\t\tchanDim = -1\n","\n","\t\t# if we are using \"channels first\", update the input shape\n","\t\t# and channels dimension\n","\t\tif K.image_data_format() == \"channels_first\":\n","\t\t\tinputShape = (depth, height, width)\n","\t\t\tchanDim = 1\n","\n","\t\t# define the model input and first CONV module\n","\t\tinputs = Input(shape=inputShape)\n","\t\t# 1st conv module\n","\t\tx = ESLR_Net3.conv_module(inputs, 32, 5, 5, (2,2), chanDim, reg=reg)\n","\t\tx = ESLR_Net3.conv_module(x, 32, 3, 3, (1,1), chanDim, reg=reg)\n","\t\t\n","\t\t# 1st pool module\n","\t\tx = MaxPooling2D((2,2),strides=(2,2), padding=\"same\")(x)\n","\t\tx = Dropout(0.1)(x)\n","\t\t#x = TDGPerNet.pool_mod(x, (2,2), (2,2))\n","\t\t\n","\t\t# 2nd conv module\n","\t\tx = ESLR_Net3.conv_module(x, 64, 3, 3, (1,1), chanDim, reg=reg)\n","\t\tx = ESLR_Net3.conv_module(x, 64, 3, 3, (1,1), chanDim, reg=reg)\n","\t\t\n","\t\t# 2nd pool module\n","\t\tx = MaxPooling2D((2,2),strides=(2,2), padding=\"same\")(x)\n","\t\tx = Dropout(0.1)(x)\n","\t\t#x = TDGPerNet.pool_mod(x, (2,2), (2,2))\n","\t\t\n","\t\t# 1st three inception modules\n","\t\tx = ESLR_Net3.inception_mod(x, 64, 32, 16, chanDim, reg=reg)\n","\t\tx = ESLR_Net3.inception_mod(x, 96, 48, 16, chanDim, reg=reg)\n","\t\tx = ESLR_Net3.inception_mod(x, 128, 64, 24, chanDim, reg=reg)\n","\t\t\n","\t\t# 3rd pool module\n","\t\tx = ESLR_Net3.pool_mod(x, (2,2), (2,2))\n","\n","\t\t# 2nd two inception modules\t\t\n","\t\tx = ESLR_Net3.inception_mod(x, 160, 64, 24, chanDim, reg=reg)\n","\t\tx = ESLR_Net3.inception_mod(x, 192, 64, 32, chanDim, reg=reg)\n","\t\t\n","\t\t# 4th pool module\n","\t\tx = ESLR_Net3.pool_mod(x, (2,2), (2,2))\n","\n","\t\t# AVG POOL => DO\n","\t\tx = AveragePooling2D((7,7))(x)\n","\t\tx = Dropout(0.4)(x)\n","\t\t\n","\n","\t\t# flatten , softmax\n","\t\tx = Flatten()(x)\n","\t\tx = Dense(12, kernel_regularizer=l2(reg))(x)\n","\t\tx = Activation(\"softmax\")(x)\n","\n","\t\t# create the model\n","\t\tmodel = Model(inputs, x, name=\"ESLR_Net3\")\n","\t\t# return the constructed network architecture\n","\t\treturn model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RZx6apAinRaL"},"outputs":[],"source":["# TDGPerNetr - 16 trained on image size (224, 224)\n","# import the necessary packages\n","from keras.models import Sequential\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import AveragePooling2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.core import Activation\n","from keras.layers.core import Flatten\n","from keras.layers.core import Dropout\n","from keras.layers.core import Dense\n","from keras.layers import Input\n","from keras.models import Model\n","from keras.layers import concatenate\n","from keras.regularizers import l2\n","from keras import backend as K\n","\n","class ESLR_Net4:\n","\t@staticmethod\n","\tdef conv_module(x, K, kX, kY, stride, chanDim, padding=\"same\", reg=0.0005):\n","\t\t#initialize the CONV, BN, and RELU layer names\n","\n","\t\t# define a CONV => BN => RELU pattern\n","\t\tx = Conv2D(K, (kX, kY), strides=stride, padding=padding, kernel_regularizer=l2(reg))(x)\n","\t\tx = Activation(\"relu\")(x)\n","\t\t#x = BatchNormalization(axis=chanDim)(x)\n","\t\t\n","\t\t# return the block\n","\t\treturn x\n","\n","\t@staticmethod\n","\tdef pool_mod(x, psize, stride):\n","\t\tmaxim = MaxPooling2D(pool_size=psize,strides=stride)(x)\n","\t\tavrg = AveragePooling2D(pool_size=psize, strides=stride)(x)\n","\n","\t\t# concatenate maxpooling and averagepooling\n","\t\tx = concatenate([maxim, avrg])\n","\t\t#x = Dropout(dropout)(x)\n","\t\t# return the block\n","\t\treturn x\n","\n","\t@staticmethod\n","\tdef inception_mod(x, num1x1, num3x3, num5x5, chanDim, reg=0.0005):\n","\t\t# define the first branch of the Inception module consisting\n","\t\t# of 1 x 1 convolutions\n","\t\tfirst = ESLR_Net4.conv_module(x, num1x1, 1, 1, (1,1), chanDim, reg=reg)\n","\t\t# define the second branch of the Inception module consisting\n","\t\t# of 1 x 1 and 3 x 3 convolutions\n","\t\t#second = TDGPerNetr.conv_module(x, num3x3Reduce, 1, 1, (1,1), chanDim, reg=reg)\n","\t\tsecond = ESLR_Net4.conv_module(x, num3x3, 3, 3, (1,1), chanDim, reg=reg)\n","\t\t# define the third branch of the Inception module consisting\n","\t\t# of 1 x 1 and 5 x 5 convolutions\n","\t\t#third = TDGPerNetr.conv_module(x, num5x5Reduce, 1, 1, (1,1), chanDim, reg=reg)\n","\t\tthird = ESLR_Net4.conv_module(x, num5x5, 5, 5, (1,1), chanDim, reg=reg)\n","\n","\t\tx = concatenate([first, second, third], axis = chanDim)\n","\n","\t\t# return the block\n","\t\treturn x\n","\n","\t@staticmethod\n","\tdef build_model(width, height, depth, classes, reg=0.0005):\n","\t\t# initialize the model along with the input shape to be\n","\t\t# \"channels last\" and the channels dimension itself\n","\t\t# model = Sequential()\n","\t\tinputShape = (height, width, depth)\n","\t\tchanDim = -1\n","\n","\t\t# if we are using \"channels first\", update the input shape\n","\t\t# and channels dimension\n","\t\tif K.image_data_format() == \"channels_first\":\n","\t\t\tinputShape = (depth, height, width)\n","\t\t\tchanDim = 1\n","\n","\t\t# define the model input and first CONV module\n","\t\tinputs = Input(shape=inputShape)\n","\t\t# 1st conv module\n","\t\tx = ESLR_Net4.conv_module(inputs, 32, 5, 5, (2,2), chanDim, reg=reg)\n","\t\tx = ESLR_Net4.conv_module(x, 32, 3, 3, (1,1), chanDim, reg=reg)\n","\t\t\n","\t\t# 1st pool module\n","\t\tx = ESLR_Net4.pool_mod(x, (2,2), (2,2))\n","\t\t\n","\t\t# 2nd conv module\n","\t\tx = ESLR_Net4.conv_module(x, 64, 3, 3, (1,1), chanDim, reg=reg)\n","\t\tx = ESLR_Net4.conv_module(x, 64, 3, 3, (1,1), chanDim, reg=reg)\n","\t\t\n","\t\t# 2nd pool module\n","\t\tx = ESLR_Net4.pool_mod(x, (2,2), (2,2))\n","\t\t\n","\t\t# 1st three inception modules\n","\t\tx = ESLR_Net4.inception_mod(x, 64, 32, 16, chanDim, reg=reg)\n","\t\tx = ESLR_Net4.inception_mod(x, 96, 48, 16, chanDim, reg=reg)\n","\t\tx = ESLR_Net4.inception_mod(x, 128, 64, 24, chanDim, reg=reg)\n","\t\t\n","\t\t# 4th pool module\n","\t\tx = ESLR_Net4.pool_mod(x, (2,2), (2,2))\n","\n","\t\t# 2nd two inception modules\t\t\n","\t\tx = ESLR_Net4.inception_mod(x, 160, 64, 24, chanDim, reg=reg)\n","\t\tx = ESLR_Net4.inception_mod(x, 192, 64, 32, chanDim, reg=reg)\n","\t\t\n","\t\t# 5th pool module\n","\t\tx = ESLR_Net4.pool_mod(x, (2,2), (2,2))\n","\n","\t\t# AVG POOL => DO\n","\t\tx = AveragePooling2D((7,7))(x)\n","\t\tx = Dropout(0.4)(x)\n","\t\t\n","\n","\t\t# flatten , softmax\n","\t\tx = Flatten()(x)\n","\t\tx = Dense(30, kernel_regularizer=l2(reg))(x)\n","\t\tx = Activation(\"softmax\")(x)\n","\n","\t\t# create the model\n","\t\tmodel = Model(inputs, x, name=\"ESLR_Net4\")\n","\t\t# return the constructed network architecture\n","\t\treturn model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o6_W_ddj-I6u"},"outputs":[],"source":["num_features = 32\n","num_labels = 30\n","class Model1:\n","  def build_model(input_shape=(128,128,3)):\n","    model = Sequential()\n","    model.add(Conv2D(1, kernel_size=(1, 1), activation='relu', input_shape=input_shape, data_format='channels_last', kernel_regularizer=l2(0.01)))\n","    model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu'))\n","    model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Dropout(0.5))\n","\n","    model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Dropout(0.5))\n","\n","    model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Dropout(0.5))\n","\n","    model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    model.add(Dropout(0.5))\n","\n","    model.add(Flatten())\n","\n","    model.add(Dense(2*2*2*num_features, activation='relu'))\n","    model.add(Dropout(0.4))\n","    model.add(Dense(2*2*num_features, activation='relu'))\n","    model.add(Dropout(0.4))\n","    model.add(Dense(2*num_features, activation='relu'))\n","    model.add(Dropout(0.5))\n","\n","    model.add(Dense(num_labels, activation='softmax'))\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I02W3ZPG-JCH"},"outputs":[],"source":["gen = ImageDataGenerator(horizontal_flip=True,\n","                        vertical_flip=True)\n","train_generator_1 = gen.flow(trainX, trainY, batch_size=batch_size)\n","test_generator_1 = gen.flow(testX, testY, batch_size=batch_size)\n","\n","print(\"[INFO] training network...\")\n","opt = Adam(lr=1e-3, decay=1e-3 / 50)\n","model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n","\tmetrics=[\"accuracy\"])\n","H = model.fit_generator(train_generator_1, steps_per_epoch=batch_size, epochs=no_epoch,\n","                 validation_data=(testX,testY))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ASE3ltmC_StX"},"outputs":[],"source":["class Model2:\n","  def build_model(input_shape=(128,128,3)):\n","    model = Sequential()\n","    model.add(Conv2D(1, kernel_size=(1, 1), activation='relu', input_shape=input_shape, data_format='channels_last', kernel_regularizer=l2(0.01)))\n","    model.add(Conv2D(10, (5,5), activation='relu'))\n","    model.add(MaxPooling2D())\n","    model.add(Dropout(0.1))\n","    model.add(Conv2D(10, (5,5), activation='relu'))\n","    model.add(MaxPooling2D())\n","    model.add(Dropout(0.15))\n","    model.add(Conv2D(10, (3,3), activation='relu'))\n","    model.add(MaxPooling2D()) \n","    model.add(Dropout(0.1))\n","\n","    model.add(Flatten())\n","\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(30, activation='softmax'))\n","    return model\n","\n","  # TODO - replace "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dlijDK6e_TDO"},"outputs":[],"source":["class Model3:\n","  def build_model(input_shape=(128,128,3)):\n","    model = Sequential()\n","    model.add(Conv2D(1, kernel_size=(1, 1), activation='relu', input_shape=input_shape, data_format='channels_last', kernel_regularizer=l2(0.01)))\n","    model.add(Conv2D(64, (5, 5), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n","    model.add(Dropout(0.2))\n","\n","    model.add(Conv2D(64, (3, 3), activation='relu'))\n","    model.add(Conv2D(64, (3, 3), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n","    model.add(Dropout(0.2))\n","    \n","    model.add(Conv2D(128, (3, 3), activation='relu'))\n","    model.add(Conv2D(128, (3, 3), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n","    model.add(Dropout(0.2))\n","    \n","    model.add(Flatten())\n","\n","    model.add(Dense(1024, activation='relu'))\n","    model.add(Dropout(0.1))\n","    model.add(Dense(1024, activation='relu'))\n","    model.add(Dropout(0.1))\n","\n","    model.add(Dense(30, activation='softmax'))\n","    return model\n","\n","  # TODO - replace MaxPooling with stochastic pooling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ERHD8zkl-JKU"},"outputs":[],"source":["from keras.applications import VGG16\n","from keras.models import Model\n","class Model4:\n","  def build_model():\n","    vgg = VGG16(include_top=False, input_shape=(128,128,3))\n","    k = Flatten()(vgg.output)\n","    k = Dense(256, activation='relu')(k)\n","    k = Dropout(0.2)(k)\n","    k = Dense(128, activation='relu')(k)\n","    k = Dropout(0.2)(k)\n","    k = Dense(64, activation='relu')(k)\n","\n","    pred = Dense(30, activation='softmax')(k)\n","    model = Model(input=vgg.input, output=pred)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dAfF5yjjazzO"},"outputs":[],"source":["from __future__ import print_function\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Convolution2D, MaxPooling2D\n","from keras.optimizers import Adadelta\n","from keras.utils import np_utils\n","from keras.regularizers import l2 #, activity_l2\n","class Model5:\n","  def build_model():\n","      model = Sequential()\n","      #input_shape=(66,66, 3) = ukuran gambar\n","      model.add(Conv2D(8, (3, 3), padding=\"same\", input_shape=(128,128, 3)))\n","      model.add(Activation(\"relu\"))\n","      model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","      model.add(Conv2D(16, (3, 3), padding=\"same\"))\n","      model.add(Activation(\"relu\"))\n","      model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","      model.add(Conv2D(32, (3, 3), padding=\"same\"))\n","      model.add(Activation(\"relu\"))\n","      model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","      #flatten = di jadikan 1 dimensi\n","      model.add(Flatten())\n","      #Dense = banyak kelas\n","      model.add(Dense(30))\n","      model.add(Activation(\"softmax\"))\n","      return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pbQhmGbbZ3jF"},"outputs":[],"source":["import numpy as np\n","import cv2\n","\n","class gabfilter:\n","\t@staticmethod\n","\tdef build_filters():\n","\t\tfilters = []\n","\t\tksize = 31\n","\t\tfor theta in np.arange(0, np.pi, np.pi / 16):\n","\t\t\tfor freq in np.arange(0.1, 1, 0.1):\n","\t\t\t\t#cv2.getGaborKernel(ksize, sigma, theta, freq, gamma, psi, ktype)\n","\t\t\t\tkern = cv2.getGaborKernel((ksize, ksize), 4.0, theta, freq, 0.5, 0, ktype=cv2.CV_32F)\n","\t\t\t\tkern /= 1.5*kern.sum()\n","\t\t\t\tfilters.append(kern)\n","\t\treturn filters\n","\t\n","\tdef process(img, filters):\n","\t\taccum = np.zeros_like(img)\n","\t\tfor kern in filters:\n","\t\t\tfimg = cv2.filter2D(img, cv2.CV_8UC3, kern)\n","\t\t\tnp.maximum(accum, fimg, accum)\n","\t\t\treturn accum"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_tsUhFjOZ3yI"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Sat Jun 20 16:47:49 2020\n","\n","@author: wal\n","\"\"\"\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, AveragePooling2D\n","from keras import backend as K\n","\n","\n","class ESLR_Net_Hand_Gesture:\n","    @staticmethod\n","    def build_model(width, height, depth, classes):\n","        # initialize the model along with the input shape to be\n","        # \"channels last\" and the channels dimension itself\n","        model = Sequential()\n","        inputShape = (height, width, depth)\n","        chanDim = -1\n","\n","        # if we are using \"channels first\", update the input shape\n","        # and channels dimension\n","        if K.image_data_format() == \"channels_first\":\n","            inputShape = (depth, height, width)\n","            chanDim = 1\n","        model.add(Conv2D(32, (7, 7), padding=\"same\", strides=(2,2),\n","                         input_shape=inputShape))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\t\t\n","        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","        model.add(Conv2D(32, (7, 7), padding=\"same\", strides=(2,2),\n","                         input_shape=inputShape))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\t\t\n","        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","        model.add(Dropout(0.5))\n","\n","\n","\n","\n","        model.add(Conv2D(32, (3, 3), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Conv2D(32, (5, 5), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(Conv2D(32, (3, 3), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","        model.add(Conv2D(64, (3, 3), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Conv2D(64, (5, 5), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","        model.add(Conv2D(64, (3, 3), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Conv2D(64, (5, 5), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Dropout(0.5))\n","\n","\n","\n","        model.add(Conv2D(64, (3, 3), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))\n","        #model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Dropout(0.5))\n","\n","        \n","        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(Conv2D(128, (3, 3), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))\n","        model.add(Conv2D(128, (3, 3), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))\n","        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(Conv2D(128, (3, 3), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))\n","        model.add(Conv2D(128, (3, 3), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))\n","        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Dropout(0.5))\n","\n","\n","\n","        model.add(Flatten())\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Dropout(0.5))\n","\n","\t\t# softmax classifier\n","        model.add(Dense(30))\n","        model.add(Activation(\"softmax\"))\n","\n","\t\t# return the constructed network architecture\n","        return model\n","\n","        \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UaLOppZLtS3V"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, AveragePooling2D\n","from keras import backend as K\n","\n","\n","class ESLR_Net_Facial_Expression:\n","    @staticmethod\n","    def build_model(width, height, depth, classes):\n","        # initialize the model along with the input shape to be\n","        # \"channels last\" and the channels dimension itself\n","        model = Sequential()\n","        inputShape = (height, width, depth)\n","        chanDim = -1\n","\n","        # if we are using \"channels first\", update the input shape\n","        # and channels dimension\n","        if K.image_data_format() == \"channels_first\":\n","            inputShape = (depth, height, width)\n","            chanDim = 1\n","            \n","            \n","        model.add(Conv2D(32, (3, 3), padding=\"same\", strides=(2,2),\n","                         input_shape=(128,128,3)))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\t\t\n","        #model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","        model.add(Dropout(0.5))\n","      \n","        \n","        model.add(Conv2D(32, (1, 1), padding=\"same\", strides=(2,2),\n","                         input_shape=inputShape))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\t\t\n","        model.add(Conv2D(32, (3, 3), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))\n","        model.add(Conv2D(32, (1, 1), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\t\t\n","        model.add(Conv2D(32, (3, 3), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))\n","        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Dropout(0.5))\n","\n","\n","        model.add(Conv2D(64, (1, 1), padding=\"same\", strides=(2,2),\n","                         input_shape=inputShape))\n","        model.add(Activation(\"relu\"))\n","        model.add(Conv2D(64, (3, 3), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))        \n","        model.add(Conv2D(64, (1, 1), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))\n","        model.add(Conv2D(64, (3, 3), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))\n","        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","        model.add(Conv2D(64, (3, 3), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))  \n","        model.add(Conv2D(64, (3, 3), padding=\"same\", strides=(2,2)))      \n","        model.add(Activation(\"relu\"))\n","        model.add(Conv2D(128, (3, 3), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))        \n","        model.add(Conv2D(128, (1, 1), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))\n","        model.add(Conv2D(128, (3, 3), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))\n","        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","        model.add(Conv2D(128, (3, 3), padding=\"same\", strides=(2,2)))\n","        model.add(Activation(\"relu\"))   \n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Dropout(0.5))\n","\n","        \n","        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","\n","        model.add(Flatten())\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chanDim))\n","        model.add(Dropout(0.5))\n","\n","\t\t# softmax classifier\n","        model.add(Dense(5))\n","        model.add(Activation(\"softmax\"))\n","\n","\t\t# return the constructed network architecture\n","        return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DZx_Dj74tSl-"},"outputs":[],"source":["class Segmentation:    \n","    def thresholdIntegral1(inputMat,s,T = 0.15):\n","        outputMat=np.zeros(inputMat.shape)\n","        nRows = inputMat.shape[0]\n","        nCols = inputMat.shape[1]\n","        S = int(max(nRows, nCols) / 8)\n","        s2 = int(S / 4)\n","        for i in range(nRows):\n","            y1 = i - s2\n","            y2 = i + s2\n","            if (y1 < 0) :\n","                y1 = 0\n","            if (y2 >= nRows):\n","                y2 = nRows - 1\n","            for j in range(nCols):\n","                x1 = j - s2\n","                x2 = j + s2\n","                if (x1 < 0) :\n","                    x1 = 0\n","                if (x2 >= nCols):\n","                    x2 = nCols - 1\n","                count = (x2 - x1)*(y2 - y1)\n","                sum=s[y2][x2]-s[y2][x1]-s[y1][x2]+s[y1][x1]\n","                if ((int)(inputMat[i][j] * count) < (int)(sum*(1.0 - T))):\n","                    outputMat[i][j] = 255\n","        return outputMat\n","    def segment_steem(image):  \n","        ratio=1\n","        #image = cv2.imdecode(np.fromfile('data/im (6).png', dtype=np.uint8), 0)\n","        image = cv2.resize(image, (int(image.shape[1] / ratio), int(image.shape[0] / ratio)), cv2.INTER_NEAREST)    \n","        retval, otsu = cv2.threshold(image, 0, 255, cv2.THRESH_OTSU)\n","        roii = cv2.integral(image)\n","        for j in range(1):\n","            thresh = Segmentation.thresholdIntegral1(image, roii)\n","        print('success')\n","        return thresh\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FL8S-kNLa4c1"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.patches import Rectangle\n","from matplotlib.patches import Circle\n","from mtcnn.mtcnn import MTCNN\n","import cv2\n","y1=0\n","x1=0\n","width=0\n","height=0\n","x2=0\n","y2=0\n","class Segment_face():\n","    def face_Segment(img):\n","        detector = MTCNN()\n","        # detect faces in the image\n","        faces = detector.detect_faces(img)\n","        #print(len(faces))\n","        for i in range(len(faces)):\n","            # get coordinates\n","            x1, y1, width, height = faces[i]['box']\n","            x2, y2 = x1 + width, y1 + height\n","        img=img[y1:y2, x1:x2]\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","        print('success')\n","        return img\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lmjI8cV6UyPW"},"outputs":[],"source":["import cv2\n","from cv2 import destroyAllWindows\n","from cv2 import CascadeClassifier\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.patches import Rectangle\n","from matplotlib.patches import Circle\n","class Segment_face():\n","    def face_Segment(img):\n","\n","      detector = CascadeClassifier('/content/drive/My Drive/Dataset/haarcascade_frontalface_default.xml')\n","      # perform face detection\n","      faces = detector.detectMultiScale(img)\n","      for i in range(len(faces)):\n","        # get coordinates\n","        x1, y1, width, height = faces[i]\n","        x2, y2 = x1 + width, y1 + height\n","      data=img[y1:y2, x1:x2]\n","      gray = cv2.cvtColor(data, cv2.COLOR_BGR2GRAY)\n","      print('success')\n","      return img"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130},"executionInfo":{"elapsed":412,"status":"error","timestamp":1677649930210,"user":{"displayName":"Getie Balew","userId":"04202773499671067541"},"user_tz":480},"id":"G3XkmZIlU_Eg","outputId":"69e5a0fc-a212-44e9-d14a-d6aeb29388ef"},"outputs":[],"source":["import cv2\n","import numpy as np\n","class Segment_skin():\n","    def skin_Segment(img):\n","\n","        img_YCrCb = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB)\n","        YCrCb_mask = cv2.inRange(img_YCrCb, (0, 135, 85), (255,180,135)) \n","        YCrCb_mask = cv2.morphologyEx(YCrCb_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n","    \n","        YCrCb_result = cv2.bitwise_not(YCrCb_mask)\n","    \n","        img2=img\n","        for i in range(img2.shape[0]):\n","            for j in range(img2.shape[1]):\n","                if YCrCb_result[i,j] != 0:\n","                    img2[i,j,0] = 0\n","                    img2[i,j,1] = 0\n","                    img2[i,j,2] = 0\n","    \n","        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n","        YCrCb_mask = cv2.erode(YCrCb_mask, kernel, iterations = 2)\n","        YCrCb_mask = cv2.dilate(YCrCb_mask, kernel, iterations = 2)\n","        print('sucess')\n","        return img2\n","        #return YCrCb_result\n","print('success')\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
